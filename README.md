# ğŸ‘• Virtual Try-On Pipeline (IDM-VTON + Qwen2.5 + SAM2 + Florence2 + Wan2.1)

This project implements a modular, intelligent **virtual try-on** system using segmentation-guided generative modeling and modern vision-language reasoning. It allows users to upload a garment and a photo of a person, and generates a realistic image of the person wearing the garment. A 360Â° walk-around video of the try-on result is also under integration.

---

## ğŸš€ Demo Features

* ğŸ“· Upload person + garment images
* ğŸ§  Automatic garment description & position (upper/lower) detection via **Qwen2.5 VL**
* ğŸ“¦ Region detection with **Florence-2**
* âœ‚ï¸ Fine-grained mask generation with **SAM2**
* ğŸ¨ Virtual try-on using **IDM-VTON**
* ğŸ®ï¸ (WIP) Generate 360Â° turntable-style try-on video using **Wan2.1 I2V**
* ğŸ–¥ï¸ User-friendly interface via **Streamlit**

---

## ğŸ› ï¸ Installation & Setup

Follow the steps below to set up and run the Virtual Try-On (VTO) demo locally:

### 1. Clone the Repository

```bash
git clone git@github.com:alarafat/Virtual-Try-On.git
cd Virtual-Try-On
```

### 2. Create and Activate Conda Environment

Create the `vto` environment using the provided `environment.yml` file:

```bash
conda env create -f environment.yml
conda activate vto
```

### 3. Install SAM2 Dependency

Navigate to the SAM2 dependency directory and install it:

```bash
cd dependencies/sam2
pip install -e .
```

### 4. Run the Streamlit Demo

Navigate to the IDM-VTON directory and start the demo:

```bash
cd ../IDM-VTON
streamlit run gradio_demo/demo.py
```

### 5. Access the Demo

Once running, open your browser and go to:

```
http://localhost:8501
```

You should now see the Virtual Try-On interface.

---

> **âš ï¸ Note:**
> This codebase has been updated for compatibility with `transformers >= 4.51.3`.
> Older versions may cause failures when loading Florence-2 or Qwen2.5.
> Make sure to install:
>
> ```bash
> pip install transformers==4.51.3
> ```

> Also, download required model checkpoints for SAM2, IDM-VTON, and Wan2.1. Place them under their respective directories in `dependencies/`. For issues or troubleshooting, please refer to the documentation or raise an issue in the repository.



---

## ğŸ“· Pipeline Overview

```
Garment Image â”€â”
              â”œâ”€â–¶ Qwen2.5 â†’ [Garment position + Description]
Person Image <----------------------|
     â–¼
Florence-2 â†’ Bounding Box
     â–¼
SAM2       â†’ Segmentation Mask
     â–¼
IDM-VTON   â†’ Try-On Image
     â–¼
WaN I2V    â†’ (WIP) 360Â° Rotating Try-On Video
```

---

## ğŸ“‹ Step-by-Step Process

1. **User uploads** a photo of a person and a clothing image.
2. **Qwen2.5**:
   * Classifies the garment as upper/lower body
   * Generates a descriptive prompt (e.g., "short-sleeve floral blouse")
3. **Florence-2** detects bounding box of the relevant region (e.g., â€œupper-body clothâ€).
4. **SAM2** uses that box to create a high-quality segmentation mask.
5. **IDM-VTON** receives:
   * Person image
   * Cloth image
   * Mask
   * Prompt (garment description came out of Qwen2.5)
     And synthesizes a realistic try-on image.
6. *(WIP)* **WaN I2V** generates a 360Â° rotating video from the try-on image.
7. *(WIP)* **SDXL** to generate synthetic person images to try the dress on. 
---

## ğŸ“Š Results

### ğŸ” Input
<table>
  <tr>
    <td align="center"><strong>Person Image</strong></td>
    <td align="center"><strong>Garment Image</strong></td>
  </tr>
  <tr>
    <td><img src="git_images/person_image.png" width="250"/></td>
    <td><img src="git_images/garment_image.png" width="250"/></td>
  </tr>
</table>

---

### ğŸ¯ Virtual Try-On Results

<table>
  <tr>
    <td align="center"><strong>ğŸ”¬ Our Method (Florence2 + SAM2 + IDM-VTON)</strong></td>
    <td align="center"><strong>ğŸ“¦ IDM-VTON</strong></td>
  </tr>
  <tr>
    <td><img src="git_images/my_result.png" width="450"/></td>
    <td><img src="git_images/idm_vton_result.png" width="450"/></td>
  </tr>
</table>


âœ… **Observation**:  
> Our pipeline, integrating **vision-language reasoning and precise segmentation**, produced a **sharper, more accurate, and realistic result** compared to the default IDM-VTON output.  
> The mask quality and garment alignment were visibly superior, especially around sleeve boundaries and contour preservation.


## ğŸ”® Outlook
This prototype already shows **notable quality improvements** over the baseline IDM-VTON, particularly in segmentation precision and output realism. Going forward, I aim to
combine several advanced AI techniques to deliver a next-generation virtual try-on experience. Future enhancements include:

* ğŸ®ï¸ **360Â° Walk-Around View:** Ongoing integration of Wan2.1 I2V to produce dynamic turntable videos
* ğŸ§  **Full Auto Mode:** Auto cloth detection + prompt generation with Qwen2.5
* ğŸ’¡ **Multi-Garment Try-On:** Support for layering (tops + bottoms + accessories)
* ğŸ“¸ **Real-Time Webcam Mode**
* ğŸ“¦ **API Plugin:** Shopify / WooCommerce integrations
* ğŸ“± **Mobile Inference:** Quantized ONNX + TensorRT versions for lightweight try-on apps

---

## ğŸ§° Troubleshooting

### âŒ RuntimeError: Input type (float) and bias type (Half)

This may happen when loading Florence2 or using mixed precision in Torch.
âœ… Fix: Make sure inputs are cast properly or disable autocast temporarily.

### âŒ AttributeError: 'DaViT' object has no attribute '\_initialize\_weights'

This occurs when using Florence2 with older `transformers` versions.
âœ… Fix: Use `transformers >= 4.51.3`.

---

## ğŸ“ Project Structure

```
VTO/
â”œâ”€â”€ demo.py                  # Main Streamlit demo
â”œâ”€â”€ mask_generator.py        # SAM2 + Florence2 integration
â”œâ”€â”€ dependencies/
â”‚   â”œâ”€â”€ IDM-VITON/           # VTON source and weights
â”‚   â””â”€â”€ sam2/                # Segment Anything v2
```

---

## ğŸ§  Credits

* [IDM-VTON](https://github.com/yisol/IDM-VTON)
* [Qwen2.5](https://huggingface.co/Qwen)
* [Florence-2](https://huggingface.co/microsoft/Florence-2)
* [SAM2](https://github.com/facebookresearch/sam2)
* [Wan2.1 I2V](https://github.com/Wan-Video/Wan2.1)

---

## ğŸ“ Contact

> Created as part of a technical challenge on intelligent fashion try-on.
> If you're interested in extending this to production or want to collaborate, feel free to reach out.
